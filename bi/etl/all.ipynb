{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "# Lista wszystkich kolumn, które mogą wystąpić w danych\n",
    "columns_to_check = [\n",
    "    'latitude', 'multilocation', 'longitude', 'remote', 'address_text', 'published_at',\n",
    "    'street', 'company_name', 'skills', 'marker_icon', 'display_offer', 'country_code',\n",
    "    'way_of_apply', 'experience_level', 'id', 'remote_interview', 'company_url', 'company_size',\n",
    "    'workplace_type', 'open_to_hire_ukrainians', 'title', 'city'\n",
    "]\n",
    "\n",
    "def load_data_from_files(folder_path):\n",
    "    all_files = glob(os.path.join(folder_path, '*.json'))\n",
    "    data_list = []\n",
    "    for file in all_files:\n",
    "        with open(file, 'r') as f:\n",
    "            data_list.extend(json.load(f))\n",
    "    \n",
    "    # Konwersja do DataFrame i dodanie brakujących kolumn z wartością None\n",
    "    df = pd.DataFrame(data_list)\n",
    "    for column in columns_to_check:\n",
    "        if column not in df.columns:\n",
    "            df[column] = None\n",
    "            \n",
    "    return df"
   ],
   "id": "f86595655571cc46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_dim_company(df):\n",
    "    dim_company = df[['company_name', 'company_url', 'company_size']].drop_duplicates().reset_index(drop=True)\n",
    "    dim_company['company_id'] = dim_company.index + 1\n",
    "    return dim_company\n",
    "\n",
    "def create_dim_location(df):\n",
    "    dim_location = df[['street', 'city', 'country_code', 'latitude', 'longitude']].drop_duplicates().reset_index(drop=True)\n",
    "    dim_location['location_id'] = dim_location.index + 1\n",
    "    return dim_location\n",
    "\n",
    "def create_dim_skills(df):\n",
    "    skills_expanded = df.explode('skills')[['id', 'skills']]\n",
    "    skills_expanded = pd.concat([skills_expanded.drop(['skills'], axis=1), skills_expanded['skills'].apply(pd.Series)], axis=1)\n",
    "    skills_expanded = skills_expanded.rename(columns={'name': 'skill_name', 'level': 'skill_level'}).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    dim_skills = skills_expanded[['skill_name', 'skill_level']].drop_duplicates().reset_index(drop=True)\n",
    "    dim_skills['skill_id'] = dim_skills.index + 1\n",
    "    return dim_skills, skills_expanded\n",
    "\n",
    "def create_employmet_dim(df):\n",
    "    dim_emp = df[\"workplace_type\"].drop_duplicates().reset_index(\n",
    "        drop=True)\n",
    "    dim_emp['workplace_type_id'] = dim_emp.index + 1\n",
    "    return dim_emp\n",
    "\n",
    "def create_workplace_dim(df):\n",
    "    dim_workplace = df[\"workplace_type\"].drop_duplicates().reset_index(\n",
    "        drop=True)\n",
    "    dim_workplace['workplace_type_id'] = dim_workplace.index + 1\n",
    "    return dim_workplace"
   ],
   "id": "52235244c28dc0bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_fact_table(df, dim_company, dim_location, skills_expanded, dim_skills):\n",
    "    # Łączenie identyfikatorów firmy i lokalizacji do tabeli faktów\n",
    "    df = df.merge(dim_company, on=['company_name', 'company_url', 'company_size'], how='left')\n",
    "    df = df.merge(dim_location, on=['street', 'city', 'country_code', 'latitude', 'longitude'], how='left')\n",
    "    df = df.merge(skills_expanded, on=['skill_name', 'skill_level'], how='left')\n",
    "    df = df.merge(dim_skills, on=['skill_name', 'skill_level'], how='left')\n",
    "    # Dodanie identyfikatorów umiejętności do tabeli umiejętności rozszerzonej\n",
    "    skills_expanded = skills_expanded.merge(dim_skills, on=['skill_name', 'skill_level'], how='left')\n",
    "\n",
    "    # Grupowanie umiejętności według id ofert pracy\n",
    "    skills_grouped = skills_expanded.groupby('id')['skill_id'].apply(list).reset_index()\n",
    "\n",
    "    # Łączenie umiejętności z tabelą faktów\n",
    "    df = df.merge(skills_grouped, on='id', how='left')\n",
    "\n",
    "    # Przekształcenie tabeli faktów, aby zawierała tylko identyfikatory oraz inne istotne kolumny\n",
    "    fact_df = df[[\n",
    "        'id', 'title', 'workplace_type', 'experience_level', 'published_at', 'remote_interview', \n",
    "        'open_to_hire_ukrainians', 'remote', 'employment_type', 'salary', 'from', 'to', 'currency', \n",
    "        'company_id', 'location_id', 'skill_id', 'multilocation', 'address_text', 'marker_icon', \n",
    "        'display_offer', 'way_of_apply'\n",
    "    ]]\n",
    "    \n",
    "    return fact_df"
   ],
   "id": "a210fe256ddbeebb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_all_folders(base_folder_path):\n",
    "    all_fact_tables = []\n",
    "    all_dim_companies = []\n",
    "    all_dim_locations = []\n",
    "    all_dim_skills = []\n",
    "\n",
    "    for folder in os.listdir(base_folder_path):\n",
    "        folder_path = os.path.join(base_folder_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            df = load_data_from_files(folder_path)\n",
    "            \n",
    "            dim_company = create_dim_company(df)\n",
    "            dim_location = create_dim_location(df)\n",
    "            dim_skills, skills_expanded = create_dim_skills(df)\n",
    "            \n",
    "            fact_df = create_fact_table(df, dim_company, dim_location, skills_expanded, dim_skills)\n",
    "            \n",
    "            all_fact_tables.append(fact_df)\n",
    "            all_dim_companies.append(dim_company)\n",
    "            all_dim_locations.append(dim_location)\n",
    "            all_dim_skills.append(dim_skills)\n",
    "    \n",
    "    # Scalanie tabel wymiarów i faktów z wszystkich folderów\n",
    "    final_fact_table = pd.concat(all_fact_tables).reset_index(drop=True)\n",
    "    final_dim_company = pd.concat(all_dim_companies).drop_duplicates().reset_index(drop=True)\n",
    "    final_dim_location = pd.concat(all_dim_locations).drop_duplicates().reset_index(drop=True)\n",
    "    final_dim_skills = pd.concat(all_dim_skills).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return final_fact_table, final_dim_company, final_dim_location, final_dim_skills\n"
   ],
   "id": "74e89f7d2d24c5f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_folder_path = '/path/to/your/base/folder'\n",
    "final_fact_table, final_dim_company, final_dim_location, final_dim_skills = process_all_folders(base_folder_path)\n"
   ],
   "id": "ec2b0b1653be0f9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
